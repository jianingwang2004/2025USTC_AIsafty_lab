{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task-1:深度模型对抗鲁棒性评估\n",
    "## Task 1.1:构建和训练神经网络\n",
    "> 模型一：SimpleCNN\n",
    "> 模型二：DeepCNN\n",
    "> 模型三：RobustCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import os\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================\n",
    "# 数据预处理部分\n",
    "# ========================\n",
    "\n",
    "# 定义图像变换：将图像转为张量，并进行归一化处理\n",
    "# MNIST 原始灰度值范围为 [0, 255]，ToTensor 会转换为 [0, 1]\n",
    "# Normalize 使其分布变为均值为 0，标准差为 1（对抗训练常用）\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5])]\n",
    ")\n",
    "\n",
    "# 加载训练集\n",
    "train_dataset = torchvision.datasets.MNIST(\n",
    "    'dataset/mnist-pytorch', # 存储路径\n",
    "    train=True, # 训练集\n",
    "    download=True, # 自动下载\n",
    "    transform=transform # 应用预处理\n",
    ")\n",
    "\n",
    "# 加载测试集\n",
    "test_dataset = torchvision.datasets.MNIST(\n",
    "    'dataset/mnist-pytorch',\n",
    "    train=False,\n",
    "    transform=transform,\n",
    ")\n",
    "\n",
    "# 封装为数据加载器，设定 batch 大小为 128\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================\n",
    "# 模型定义部分\n",
    "# ========================\n",
    "\n",
    "# -------- SimpleCNN --------\n",
    "# 简单的两层卷积神经网络，适合基础分类任务\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, 3, padding=1), # 卷积层：输入1通道，输出16通道，3x3卷积核\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2), # 下采样：2x2窗口\n",
    "            nn.Conv2d(16, 32, 3, padding=1), # 第二个卷积层\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2), # 再次下采样\n",
    "            nn.Flatten(), # 展平为向量\n",
    "            nn.Linear(32 * 7 * 7, 128), # 全连接层\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 10) # 输出层：10 类\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------- DeepCNN --------\n",
    "# 更深层次的 CNN，具有更多卷积层，提取更复杂的特征\n",
    "class DeepCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DeepCNN, self).__init__()\n",
    "        \n",
    "        # 特征提取部分（卷积层 + 激活函数 + 池化层）\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, 3, padding=1), # 输入通道数为1（灰度图像），输出32个特征图，3x3卷积核，padding=1保持尺寸\n",
    "            nn.ReLU(), # 非线性激活函数\n",
    "            nn.Conv2d(32, 64, 3, padding=1), # 将特征图从32变为64\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2), # 2x2最大池化，尺寸减半（28x28 -> 14x14）\n",
    "            nn.Conv2d(64, 128, 3, padding=1), # 将特征图从64变为128\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 128, 3, padding=1), # 继续提取更复杂的特征\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2) # 再次进行池化（14x14 -> 7x7）\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(), # 展平为一维向量，大小为128 * 7 * 7\n",
    "            nn.Linear(128 * 7 * 7, 256), # 全连接层，输出维度为256\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 10) # 最终输出10类（对应MNIST的数字0-9）\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x) # 提取特征\n",
    "        x = self.classifier(x)  # 分类输出\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 残差块定义\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        \n",
    "        # 第一个卷积层：调整通道数或空间尺寸（根据 stride\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1)\n",
    "        self.gn1 = nn.GroupNorm(4, out_channels) # 使用 GroupNorm（每组4个通道）\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        \n",
    "        # 第二个卷积层：保持尺寸和通道不变\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1)\n",
    "        self.gn2 = nn.GroupNorm(4, out_channels)\n",
    "\n",
    "        # 下采样模块：如果输入输出通道不同或尺寸变化，使用1x1卷积调整\n",
    "        self.downsample = nn.Sequential()\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.downsample = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride),\n",
    "                nn.GroupNorm(4, out_channels)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = self.downsample(x) # 残差连接的分支（shortcut）\n",
    "        out = self.conv1(x)\n",
    "        out = self.gn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.gn2(out)\n",
    "        out += identity # 残差连接：输出加上shortcut\n",
    "        return self.relu(out) # 激活后返回\n",
    "\n",
    "class DefenseCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DefenseCNN, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3, padding=1), # 初始卷积层，输入通道为1（灰度图）\n",
    "            nn.GroupNorm(4, 32),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            ResidualBlock(32, 64, stride=1), # 第一个残差块\n",
    "            nn.MaxPool2d(2), # 池化，减小空间尺寸\n",
    "            nn.Dropout(0.2), # Dropout防止过拟合\n",
    "\n",
    "            ResidualBlock(64, 128, stride=1), # 第二个残差块\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Dropout(0.3),\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(), # 展平，输入为 128 x 7 x 7\n",
    "            nn.Linear(128 * 7 * 7, 256), # 全连接层输出 256 维\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(256, 10) # 最终输出10类\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        return self.classifier(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "M1 Epoch 1/4: 100%|███████████████████████████████████| 469/469 [00:11<00:00, 39.11it/s, loss=0.153]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=1 accuracy=97.66%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "M1 Epoch 2/4: 100%|██████████████████████████████████| 469/469 [00:08<00:00, 56.16it/s, loss=0.0977]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=2 accuracy=98.39%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "M1 Epoch 3/4: 100%|██████████████████████████████████| 469/469 [00:08<00:00, 52.44it/s, loss=0.0431]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=3 accuracy=98.56%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "M1 Epoch 4/4: 100%|██████████████████████████████████| 469/469 [00:08<00:00, 54.51it/s, loss=0.0101]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=4 accuracy=98.77%\n",
      "===> Final Accuracy= 98.34%\n",
      "===> M1 model saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "M2 Epoch 1/4: 100%|██████████████████████████████████| 469/469 [00:16<00:00, 28.08it/s, loss=0.0451]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=1 accuracy=98.55%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "M2 Epoch 2/4: 100%|█████████████████████████████████| 469/469 [00:16<00:00, 28.58it/s, loss=0.00262]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=2 accuracy=99.08%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "M2 Epoch 3/4: 100%|██████████████████████████████████| 469/469 [00:17<00:00, 26.74it/s, loss=0.0058]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=3 accuracy=99.12%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "M2 Epoch 4/4: 100%|█████████████████████████████████| 469/469 [00:17<00:00, 26.16it/s, loss=0.00526]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=4 accuracy=99.19%\n",
      "===> Final Accuracy= 98.98%\n",
      "===> M2 model saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "M3 Epoch 1/4: 100%|███████████████████████████████████| 469/469 [00:43<00:00, 10.68it/s, loss=0.122]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=1 accuracy=98.18%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "M3 Epoch 2/4: 100%|██████████████████████████████████| 469/469 [01:03<00:00,  7.38it/s, loss=0.0511]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=2 accuracy=98.69%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "M3 Epoch 3/4: 100%|██████████████████████████████████| 469/469 [01:03<00:00,  7.38it/s, loss=0.0364]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=3 accuracy=98.98%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "M3 Epoch 4/4: 100%|███████████████████████████████████| 469/469 [01:06<00:00,  7.05it/s, loss=0.132]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=4 accuracy=99.04%\n",
      "===> Final Accuracy= 98.72%\n",
      "===> M3 model saved.\n"
     ]
    }
   ],
   "source": [
    "# ========================\n",
    "# 模型训练函数\n",
    "# ========================\n",
    "def train(model, train_loader, test_loader, epochs, device, model_name='Model'):\n",
    "    model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss() # 使用交叉熵损失函数\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001) # Adam 优化器\n",
    "\n",
    "    total_acc = 0.0\n",
    "    \n",
    "    for epoch in range(1, epochs + 1):\n",
    "        model.train()  # 进入训练模式\n",
    "        total_loss = 0.0\n",
    "        progress_bar = tqdm(train_loader, desc=f\"{model_name} Epoch {epoch}/{epochs}\", ncols=100)\n",
    "        \n",
    "        # -------- 训练每个 batch --------\n",
    "        for images, labels in progress_bar:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward() # 反向传播\n",
    "            optimizer.step() # 参数更新\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            progress_bar.set_postfix(loss=loss.item())\n",
    "\n",
    "        # -------- 评估模型准确率 --------\n",
    "        model.eval() # 进入评估模式\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad(): # 关闭梯度以加速\n",
    "            for images, labels in test_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                _, predicted = torch.max(outputs.data, 1) # 获取预测类别\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "        accuracy = 100 * correct / total\n",
    "        total_acc += accuracy\n",
    "\n",
    "        print(f\"epoch={epoch} accuracy={accuracy:.2f}%\")\n",
    "        \n",
    "    final_acc = total_acc / epochs\n",
    "    print(f\"===> Final Accuracy= {final_acc:.2f}%\")\n",
    "\n",
    "    torch.save(model.state_dict(), f\"{model_name}.pth\")\n",
    "    print(f\"===> {model_name} model saved.\")\n",
    "        \n",
    "# ========================\n",
    "# 主函数：依次训练三个模型\n",
    "# ========================\n",
    "def test_all_models():\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    epochs = 4 # 可以根据实际训练需求增加\n",
    "\n",
    "    model1 = SimpleCNN()\n",
    "    model2 = DeepCNN()\n",
    "    model3 = DefenseCNN()\n",
    "\n",
    "     # 分别训练并保存每个模型\n",
    "    train(model1, train_loader, test_loader, epochs, device, model_name=\"M1\")\n",
    "    train(model2, train_loader, test_loader, epochs, device, model_name=\"M2\")\n",
    "    train(model3, train_loader, test_loader, epochs, device, model_name=\"M3\")\n",
    "\n",
    "# 调用主函数，开始训练\n",
    "test_all_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1.2:评估神经网络的鲁棒性\n",
    "### 步骤一：选择三种对抗攻击方式，并报告平均对抗距离与对抗攻击成功率\n",
    "> FGSM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def fast_gradient_sign_method(model, imgs, labels, epsilon=0.02):\n",
    "    model.eval() # 模型处于评估模式\n",
    "    inp_imgs = imgs.clone().to(device).requires_grad_() # 复制一份imgs，标记为需要求梯度的张量\n",
    "    preds = model(inp_imgs) # 前向传播获取真实图像的预测结果\n",
    "    preds = F.log_softmax(preds, dim=-1) # 将预测结果转化为概率的形式 [0.2, 0.12, ...]\n",
    "\n",
    "    loss = F.nll_loss(preds, labels.to(device)) # 计算负对数似然损失(NLL loss)\n",
    "    loss.backward() # 反向传播\n",
    "\n",
    "    noise_grad = torch.sign(inp_imgs.grad.detach()).to(imgs.device) # 对抗扰动方向\n",
    "    fake_imgs = imgs + epsilon * noise_grad # 计算对抗样本\n",
    "    fake_imgs.detach_() # 分离计算图，避免后续计算梯度\n",
    "    return fake_imgs, epsilon * noise_grad\n",
    "\n",
    "def evaluate_fgsm(model_class, weight_path, data_loader, epsilon, num_samples):\n",
    "    # 实例化模型并加载预训练权重\n",
    "    model = model_class().to(device)\n",
    "    model.load_state_dict(torch.load(weight_path, map_location=device))\n",
    "    model.eval()\n",
    "    \n",
    "    # 固定随机种子以保证结果可复现\n",
    "    seed = 22051022\n",
    "    random.seed(seed)\n",
    "    \n",
    "    # 整理全部测试图像和标签\n",
    "    all_imgs, all_labels = [], []\n",
    "    for imgs, labels in data_loader:\n",
    "        all_imgs.append(imgs)\n",
    "        all_labels.append(labels)\n",
    "    all_imgs = torch.cat(all_imgs)\n",
    "    all_labels = torch.cat(all_labels)\n",
    "    \n",
    "    # 随机选择样本进行攻击\n",
    "    indices = random.sample(range(len(all_imgs)), num_samples)\n",
    "    images = all_imgs[indices]\n",
    "    labels = all_labels[indices]\n",
    "    \n",
    "    # 生成FGSM对抗样本\n",
    "    adv_images, perturbations = fast_gradient_sign_method(model, images, labels, epsilon)\n",
    "\n",
    "    # 获取模型在原图和对抗图像上的预测结果\n",
    "    with torch.no_grad():\n",
    "        preds_before = model(images.to(device)).argmax(dim=1)\n",
    "        preds_after = model(adv_images.to(device)).argmax(dim=1)\n",
    "\n",
    "    # 判断哪些样本攻击前预测正确（才算成功攻击的候选）\n",
    "    success_before = (preds_before.cpu() == labels)\n",
    "    success_after = (preds_after.cpu() == labels)\n",
    "    \n",
    "    # 标记成功被攻击的样本：攻击前正确，攻击后错误\n",
    "    success_mask = success_before & (~success_after)\n",
    "    \n",
    "    # 对这些样本计算L2扰动距离\n",
    "    pert_norms = torch.norm((adv_images - images).view(images.size(0), -1), p=2, dim=1)\n",
    "    \n",
    "    # 原始准确率、攻击后准确率\n",
    "    accuracy_before = success_before.sum().item() / len(labels)\n",
    "    accuracy_after = success_after.sum().item() / len(labels)\n",
    "    \n",
    "    # 攻击成功率 = 预测正确但被误分类的比例\n",
    "    attack_success_rate = 1.0 - accuracy_after\n",
    "    \n",
    "    # 只统计成功攻击样本的平均L2扰动距离\n",
    "    avg_perturbation = pert_norms[success_mask].mean().item() \n",
    "\n",
    "    print(f\"accuracy_before={accuracy_before:.2f} accuracy_after={accuracy_after:.2f} attack_success_rate={attack_success_rate:.2f} avg_perturbation={avg_perturbation:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_22200\\2570958830.py:23: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(weight_path, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_before=0.99 accuracy_after=0.94 attack_success_rate=0.06 avg_perturbation=2.80\n",
      "Simple\n",
      "accuracy_before=0.99 accuracy_after=0.97 attack_success_rate=0.03 avg_perturbation=2.80\n",
      "Deep\n",
      "accuracy_before=1.00 accuracy_after=0.97 attack_success_rate=0.03 avg_perturbation=2.80\n",
      "Defense\n"
     ]
    }
   ],
   "source": [
    "test_loader = DataLoader(test_dataset, batch_size=128)\n",
    "\n",
    "epsilon=0.1 # FGSM扰动强度\n",
    "num_samples=100 # 随机采样样本数用于评估\n",
    "\n",
    "stats_Simple = evaluate_fgsm(SimpleCNN, \"M1.pth\", test_loader, epsilon, num_samples)\n",
    "print(f\"Simple\")\n",
    "\n",
    "stats_Deep = evaluate_fgsm(DeepCNN, \"M2.pth\", test_loader, epsilon, num_samples)\n",
    "print(f\"Deep\")\n",
    "\n",
    "stats_Defense = evaluate_fgsm(DefenseCNN, \"M3.pth\", test_loader, epsilon, num_samples)\n",
    "print(f\"Defense\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> PGD Attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def projected_gradient_descent(model, imgs, labels, steps=4, alpha=0.02, epsilon=0.1):\n",
    "    model.eval()\n",
    "    \n",
    "    # 初始化对抗扰动\n",
    "    delta = torch.zeros_like(imgs, device=device).requires_grad_() # cuda\n",
    "    fake_imgs = imgs.to(device)\n",
    "\n",
    "    for t in range(steps):\n",
    "        # 计算当前的对抗样本\n",
    "        fake_imgs = imgs.to(device) + delta\n",
    "        fake_imgs.retain_grad()\n",
    "        \n",
    "        preds = model(fake_imgs)\n",
    "        preds = F.log_softmax(preds, dim=1)\n",
    "\n",
    "        # 计算损失函数并反向传播\n",
    "        loss = F.nll_loss(preds, labels.to(device))\n",
    "        loss.backward()\n",
    "\n",
    "        # # 提取梯度方向\n",
    "        noise_grad = fake_imgs.grad.data.sign().to(device)\n",
    "        # noise_grad = torch.sign(fake_imgs.grad.detach()).to(device)\n",
    "        fake_imgs.grad.zero_() # 清空梯度，防止梯度叠加\n",
    "\n",
    "        # 更新扰动\n",
    "        delta.data.add_(alpha * noise_grad)\n",
    "        delta.data.clamp_( - epsilon,  + epsilon) # 将对抗扰动控制在[-eps, eps]范围\n",
    "\n",
    "    return fake_imgs.to(imgs.device).detach_(), delta.detach_().to(imgs.device)\n",
    "    # return fake_imgs.to(imgs.device).detach_(), k_grad.to(imgs.device)/steps\n",
    "    \n",
    "def evaluate_pgd(model_class, weight_path, data_loader, num_samples):\n",
    "    model = model_class().to(device)\n",
    "    model.load_state_dict(torch.load(weight_path, map_location=device))\n",
    "    model.eval()\n",
    "    \n",
    "    # 设定随机种子，确保可复现\n",
    "    seed = 22051022\n",
    "    random.seed(seed)\n",
    "    \n",
    "    # 收集所有测试图像与标签\n",
    "    all_imgs, all_labels = [], []\n",
    "    for imgs, labels in data_loader:\n",
    "        all_imgs.append(imgs)\n",
    "        all_labels.append(labels)\n",
    "    all_imgs = torch.cat(all_imgs)\n",
    "    all_labels = torch.cat(all_labels)\n",
    "    \n",
    "    # 从中随机采样 num_samples 个用于评估\n",
    "    indices = random.sample(range(len(all_imgs)), num_samples)\n",
    "    images = all_imgs[indices]\n",
    "    labels = all_labels[indices]\n",
    "    \n",
    "    # 使用 PGD 生成对抗样本\n",
    "    adv_images, perturbations = projected_gradient_descent(model, images, labels)\n",
    "    \n",
    "    # 计算攻击前后的预测结果\n",
    "    with torch.no_grad():\n",
    "        preds_before = model(images.to(device)).argmax(dim=1)\n",
    "        preds_after = model(adv_images.to(device)).argmax(dim=1)\n",
    "\n",
    "    # 对比攻击前后是否预测正确\n",
    "    success_before = (preds_before.cpu() == labels)\n",
    "    success_after = (preds_after.cpu() == labels)\n",
    "    # 仅统计那些本来能正确分类但被攻击失败的样本\n",
    "    success_mask = success_before & (~success_after)\n",
    "    # L2范数的扰动大小\n",
    "    pert_norms = torch.norm((adv_images - images).view(images.size(0), -1), p=2, dim=1)\n",
    "    \n",
    "    # 指标计算\n",
    "    accuracy_before = success_before.sum().item() / len(labels)\n",
    "    accuracy_after = success_after.sum().item() / len(labels)\n",
    "    attack_success_rate = 1.0 - accuracy_after\n",
    "    \n",
    "    # 只统计成功攻击的扰动平均值\n",
    "    avg_perturbation = pert_norms[success_mask].mean().item()\n",
    "\n",
    "    print(f\"accuracy_before={accuracy_before:.2f} accuracy_after={accuracy_after:.2f} attack_success_rate={attack_success_rate:.2f} avg_perturbation={avg_perturbation:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_22200\\3941996626.py:34: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(weight_path, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_before=0.99 accuracy_after=0.95 attack_success_rate=0.05 avg_perturbation=1.40\n",
      "Simple\n",
      "accuracy_before=0.99 accuracy_after=0.99 attack_success_rate=0.01 avg_perturbation=nan\n",
      "Deep\n",
      "accuracy_before=1.00 accuracy_after=0.98 attack_success_rate=0.02 avg_perturbation=1.38\n",
      "Defense\n"
     ]
    }
   ],
   "source": [
    "num_samples = 100\n",
    "stats_Simple = evaluate_pgd(SimpleCNN, \"M1.pth\", test_loader, num_samples)\n",
    "print(f\"Simple\")\n",
    "stats_Deep = evaluate_pgd(DeepCNN, \"M2.pth\", test_loader, num_samples)\n",
    "print(f\"Deep\")\n",
    "stats_Defense = evaluate_pgd(DefenseCNN, \"M3.pth\", test_loader, num_samples)\n",
    "print(f\"Defense\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> C&W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cw_loss_untargeted(Z, delta, true_labels, c=0.5, loss_func=None):\n",
    "    # Z: 模型输出 logits\n",
    "    # true_labels: 原始标签 y\n",
    "    # delta: 扰动\n",
    "    # loss_func: 用于约束扰动的大小（一般为 MSELoss）\n",
    "\n",
    "    one_hot = F.one_hot(true_labels, num_classes=Z.shape[-1]).to(Z.device)\n",
    "    Z_y = torch.sum(Z * one_hot, dim=-1)  # 原标签的 logit 值\n",
    "    Z_not_y = torch.max(Z * (1 - one_hot), dim=-1)[0]  # 非原标签中的最大 logit 值\n",
    "\n",
    "    # 与 Targeted 不同，这里我们希望原标签的 logit 更小，非原标签的 logit 更大\n",
    "    margin = torch.clamp(Z_y - Z_not_y, min=0)  # 只有 Z_y > Z_not_y 才 penalize\n",
    "    loss = loss_func(delta, torch.zeros_like(delta)) + c * margin.sum()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cw_attack_untargeted(model, imgs, true_labels, c=1, num_epoch=50, lr=1e-2):\n",
    "    model.eval()\n",
    "    copy_imgs = imgs.clone().to(device)\n",
    "    \n",
    "    # 将图像从 [0, 1] 映射到 [-1 + ε, 1 - ε] 再取 arctanh 得到变量 w（可优化变量）\n",
    "    # 变换方式参考原始 CW 论文中提出的变量替换技巧（保证生成的图像落在合法范围内）\n",
    "    w = torch.atanh(torch.clamp(copy_imgs * 2 - 1, min=-1, max=1))\n",
    "    w = w.to(device).requires_grad_() # 设置为可优化变量\n",
    "    optimizer = torch.optim.Adam([w], lr=lr) # 优化变量 w\n",
    "    mseloss = torch.nn.MSELoss() # 用于计算扰动的最小二乘损失\n",
    "\n",
    "    # 优化循环\n",
    "    for epoch in range(num_epoch):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # 通过 tanh 逆变换将 w 变回图像空间，得到扰动 delta\n",
    "        delta = 0.5 * (torch.tanh(w) + 1) - copy_imgs\n",
    "        \n",
    "        # 计算模型在对抗图像上的输出\n",
    "        Z = model(copy_imgs + delta)\n",
    "        \n",
    "        # 计算 CW 无目标攻击的损失（包括分类置信度与扰动大小）\n",
    "        loss = cw_loss_untargeted(Z, delta, true_labels, c=c, loss_func=mseloss)\n",
    "        loss.backward() # 反向传播\n",
    "        optimizer.step() # 更新变量 w\n",
    "\n",
    "    # 最终计算对抗扰动并返回对抗图像与扰动量\n",
    "    delta = 0.5 * (torch.tanh(w) + 1) - copy_imgs\n",
    "    return (copy_imgs + delta).to(imgs.device).detach_(), delta.detach_().to(imgs.device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#整体评估逻辑依然和上两种类似\n",
    "def evaluate_cw(model_class, weight_path, data_loader, num_samples):\n",
    "    model = model_class().to(device)\n",
    "    model.load_state_dict(torch.load(weight_path, map_location=device))\n",
    "    model.eval() #评估模式\n",
    "    \n",
    "    seed = 22051022\n",
    "    random.seed(seed)\n",
    "    all_imgs, all_labels = [], []\n",
    "    for imgs, labels in data_loader:\n",
    "        all_imgs.append(imgs)\n",
    "        all_labels.append(labels)\n",
    "    all_imgs = torch.cat(all_imgs)\n",
    "    all_labels = torch.cat(all_labels)\n",
    "    \n",
    "    indices = random.sample(range(len(all_imgs)), num_samples)\n",
    "    images = all_imgs[indices]\n",
    "    labels = all_labels[indices]\n",
    "\n",
    "    target_labels = (labels + 1) % 10  # 保证目标标签不同\n",
    "\t# 计算对抗样本和扰动\n",
    "    adv_images, perturbation = cw_attack_untargeted(model, images, labels, c=1.0, num_epoch=50, lr=1e-2)\n",
    "\n",
    "\n",
    "    with torch.no_grad():\n",
    "        preds_before = model(images.to(device)).argmax(dim=1)\n",
    "        preds_after = model(adv_images.to(device)).argmax(dim=1)\n",
    "\n",
    "    success_before = (preds_before.cpu() == labels)\n",
    "    success_after = (preds_after.cpu() == labels)\n",
    "    success_mask = success_before & (~success_after)  # 攻击成功\n",
    "    pert_norms = torch.norm((adv_images - images).view(images.size(0), -1), p=2, dim=1)\n",
    "    \n",
    "    accuracy_before = success_before.sum().item() / len(labels)\n",
    "    accuracy_after = success_after.sum().item() / len(labels)\n",
    "    attack_success_rate = 1.0 - accuracy_after\n",
    "    avg_perturbation = pert_norms[success_mask].mean().item()\n",
    "\n",
    "    print(f\"accuracy_before={accuracy_before:.2f} accuracy_after={accuracy_after:.2f} attack_success_rate={attack_success_rate:.2f} avg_perturbation={avg_perturbation:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_22200\\3570220852.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(weight_path, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_before=0.99 accuracy_after=0.90 attack_success_rate=0.10 avg_perturbation=25.80\n",
      "Simple\n",
      "accuracy_before=0.99 accuracy_after=0.91 attack_success_rate=0.09 avg_perturbation=25.49\n",
      "Deep\n",
      "accuracy_before=1.00 accuracy_after=0.96 attack_success_rate=0.04 avg_perturbation=25.59\n",
      "Defense\n"
     ]
    }
   ],
   "source": [
    "num_samples = 100\n",
    "stats_Simple = evaluate_cw(SimpleCNN, \"M1.pth\", test_loader, num_samples)\n",
    "print(f\"Simple\")\n",
    "stats_Deep = evaluate_cw(DeepCNN, \"M2.pth\", test_loader, num_samples)\n",
    "print(f\"Deep\")\n",
    "stats_Defense = evaluate_cw(DefenseCNN, \"M3.pth\", test_loader, num_samples)\n",
    "print(f\"Defense\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 步骤二：比较所有神经网络的鲁棒性和准确性\n",
    "> FGSM\n",
    "\n",
    "|神经网络|accuracy_before|accuracy_after|attack_success_rate|avg_perturbation|\n",
    "|----|----|----|----|----|\n",
    "|SimpleCNN|0.99|0.94|0.06|2.80|\n",
    "|DeepCNN|0.99|0.97|0.03|2.80|\n",
    "|DefenseCNN|1.00|0.97|0.03|2.80|\n",
    "\n",
    "> PGD Attack\n",
    "\n",
    "|神经网络|accuracy_before|accuracy_after|attack_success_rate|avg_perturbation|\n",
    "|----|----|----|----|----|\n",
    "|SimpleCNN|0.99|0.95|0.05|1.40|\n",
    "|DeepCNN|0.99|0.99|0.01|nan|\n",
    "|DefenseCNN|1.00|0.98|0.02|1.38|\n",
    "\n",
    "> C&W\n",
    "\n",
    "|神经网络|accuracy_before|accuracy_after|attack_success_rate|avg_perturbation|\n",
    "|----|----|----|----|----|\n",
    "|SimpleCNN|0.99|0.90|0.10|25.80|\n",
    "|DeepCNN|0.99|0.91|0.09|25.49|\n",
    "|DefenseCNN|1.00|0.96|0.04|25.59|\n",
    "\n",
    "> 由表格可见，高准确性并不一定意味着高鲁棒性\n",
    "> 模型在不同攻击方法下鲁棒性表现不一致"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 步骤三：是否存在对 3 种攻击都鲁棒的模型\n",
    "> 由实验结果可见，DefenseCNN对三种攻击的鲁棒性都很好。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task-2:深度模型的对抗训练\n",
    "### 步骤一：选用三种对抗训练方法重新训练RobustCNN\n",
    "> FGSM-based Adversarial Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fgsm_attack(model, images, labels, epsilon=0.25):\n",
    "    images = images.clone().detach().to(images.device).requires_grad_(True)\n",
    "    outputs = model(images)\n",
    "    loss = nn.CrossEntropyLoss()(outputs, labels) # 计算交叉熵损失\n",
    "    model.zero_grad()\n",
    "    loss.backward() # 反向传播\n",
    "    grad = images.grad.data # 获取图像的梯度\n",
    "    adv_images = images + epsilon * grad.sign() # 生成对抗样本：在原图基础上添加梯度符号方向的扰动\n",
    "    adv_images = torch.clamp(adv_images, -1, 1) # 将对抗图像限制在合法范围内，MNIST 通常归一化到 [-1, 1]\n",
    "    return adv_images.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fgsm(model, train_loader, test_loader, epochs, device, model_name='FGSM_Model'):\n",
    "    model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        model.train()\n",
    "        progress_bar = tqdm(train_loader, desc=f\"{model_name} Epoch {epoch}/{epochs}\", ncols=100)\n",
    "        for images, labels in progress_bar:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            # FGSM 对抗样本生成\n",
    "            adv_images = fgsm_attack(model, images, labels)\n",
    "\n",
    "            # 合并干净样本与对抗样本\n",
    "            mixed_images = torch.cat([images, adv_images], dim=0)\n",
    "            mixed_labels = torch.cat([labels, labels], dim=0)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(mixed_images)\n",
    "            loss = criterion(outputs, mixed_labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            progress_bar.set_postfix(loss=loss.item())\n",
    "\n",
    "        # 测试精度\n",
    "        evaluate_model(model, test_loader, device, model_name)\n",
    "\n",
    "    torch.save(model.state_dict(), f\"{model_name}.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> PGD Adversarial Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pgd_attack(model, images, labels, eps=0.25, alpha=0.01, iters=40):\n",
    "    images = images.clone().detach().to(images.device)\n",
    "    ori_images = images.clone().detach()\n",
    "    \n",
    "    # 初始化扰动 delta，范围在 [-eps, eps] 之间的均匀分布\n",
    "    delta = torch.zeros_like(images).uniform_(-eps, eps).to(images.device)\n",
    "    delta.requires_grad = True\n",
    "\n",
    "    # 开始迭代更新 delta\n",
    "    for _ in range(iters):\n",
    "        outputs = model(images + delta)\n",
    "        loss = nn.CrossEntropyLoss()(outputs, labels) # 计算交叉熵损失\n",
    "        loss.backward() # 反向传播，计算 delta 的梯度\n",
    "        delta.data = (delta + alpha * delta.grad.sign()).clamp(-eps, eps) # 使用 FGSM 的方式更新扰动：沿梯度方向移动 alpha\n",
    "        delta.grad.zero_() # 清除上一轮梯度，防止累积\n",
    "    \n",
    "    adv_images = torch.clamp(images + delta.detach(), -1, 1) # 最终对抗图像限制在合法图像值范围 [-1, 1]\n",
    "    return adv_images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_pgd(model, train_loader, test_loader, epochs, device, model_name='PGD_Model'):\n",
    "    model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss() # 定义交叉熵损失函数\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001) # 使用 Adam 优化器优化模型参数\n",
    "\n",
    "    # 训练循环，共进行 epochs 个周期\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        model.train()\n",
    "        \n",
    "        # 使用 tqdm 显示训练进度条\n",
    "        progress_bar = tqdm(train_loader, desc=f\"{model_name} Epoch {epoch}/{epochs}\", ncols=100)\n",
    "        \n",
    "        # 遍历训练集中每个批次\n",
    "        for images, labels in progress_bar:\n",
    "            images, labels = images.to(device), labels.to(device) # 移动到计算设备\n",
    "\n",
    "            # 使用 PGD 生成对抗样本\n",
    "            adv_images = pgd_attack(model, images, labels, eps=0.25, alpha=0.01, iters=7)\n",
    "\n",
    "            # 计算模型在对抗样本上的损失并更新参数\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(adv_images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            progress_bar.set_postfix(loss=loss.item())\n",
    "\n",
    "        # 每轮结束后，在测试集上评估模型性能\n",
    "        evaluate_model(model, test_loader, device, model_name)\n",
    "\n",
    "    torch.save(model.state_dict(), f\"{model_name}.pth\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> TRADES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trades_loss(model, x_natural, y, optimizer, step_size=0.01, epsilon=0.25, perturb_steps=10, beta=6.0):\n",
    "    # KL 散度损失函数，用于衡量自然样本与对抗样本之间预测分布的差异\n",
    "    criterion_kl = nn.KLDivLoss(reduction='batchmean')\n",
    "    model.eval()\n",
    "\n",
    "    # 初始化对抗样本 x_adv：在自然样本基础上加入微小随机扰动\n",
    "    x_adv = x_natural.detach() + 0.001 * torch.randn_like(x_natural).to(x_natural.device)\n",
    "    \n",
    "    # 基于 KL 散度进行投影梯度下降（PGD）生成对抗样本\n",
    "    for _ in range(perturb_steps):\n",
    "        x_adv.requires_grad_()\n",
    "        with torch.enable_grad():\n",
    "            # 计算对抗样本与自然样本预测分布之间的 KL 散度\n",
    "            loss_kl = criterion_kl(\n",
    "                F.log_softmax(model(x_adv), dim=1), # 对抗样本的预测分布（log 概率）\n",
    "                F.softmax(model(x_natural), dim=1) # 自然样本的预测分布（概率）\n",
    "            )\n",
    "        # 计算损失对对抗样本的梯度\n",
    "        grad = torch.autograd.grad(loss_kl, [x_adv])[0]\n",
    "        # 沿着梯度方向更新对抗样本，step_size 控制更新步长\n",
    "        x_adv = x_adv.detach() + step_size * torch.sign(grad.detach())\n",
    "        # 将扰动限制在 epsilon 范围内，保持与原图像接近（L∞ 约束）\n",
    "        x_adv = torch.min(torch.max(x_adv, x_natural - epsilon), x_natural + epsilon)\n",
    "        # 保证对抗样本值在合法图像范围（例如 MNIST 为 [-1, 1]）\n",
    "        x_adv = torch.clamp(x_adv, -1.0, 1.0)\n",
    "\n",
    "    model.train()\n",
    "    x_adv = x_adv.detach()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # 自然样本交叉熵损失\n",
    "    logits = model(x_natural)\n",
    "    loss_natural = F.cross_entropy(logits, y)\n",
    "\n",
    "    # 对抗鲁棒性损失：对抗样本与自然样本之间预测分布的 KL 散度\n",
    "    loss_robust = criterion_kl(\n",
    "        F.log_softmax(model(x_adv), dim=1), # 对抗样本预测（log 概率）\n",
    "        F.softmax(logits, dim=1) # 自然样本预测（概率）\n",
    "    )\n",
    "\n",
    "    # 最终损失由自然损失 + beta 倍鲁棒性损失组成\n",
    "    loss = loss_natural + beta * loss_robust\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_trades(model, train_loader, test_loader, epochs, device, model_name='TRADES_Model'):\n",
    "    model.to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        model.train()\n",
    "        progress_bar = tqdm(train_loader, desc=f\"{model_name} Epoch {epoch}/{epochs}\", ncols=100)\n",
    "        for images, labels in progress_bar:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            # 计算 TRADES 对抗训练的损失\n",
    "            loss = trades_loss(model, images, labels, optimizer)\n",
    "            # 反向传播计算梯度\n",
    "            loss.backward()\n",
    "            # 更新模型参数\n",
    "            optimizer.step()\n",
    "            # 更新进度条显示当前损失值\n",
    "            progress_bar.set_postfix(loss=loss.item())\n",
    "\n",
    "        # 每个 epoch 结束后，在测试集上评估模型表现\n",
    "        evaluate_model(model, test_loader, device, model_name)\n",
    "\n",
    "    torch.save(model.state_dict(), f\"{model_name}.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_loader, device, name='Model'):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            # 取最大值对应的类别索引作为预测结果\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            # 更新总样本数\n",
    "            total += labels.size(0)\n",
    "            # 统计预测正确的样本数量\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    acc = 100 * correct / total\n",
    "    print(f\"{name} Accuracy: {acc:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FGSM_Model Epoch 1/4: 100%|████████████████████████████| 469/469 [00:19<00:00, 23.60it/s, loss=0.13]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FGSM_Model Accuracy: 98.07%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FGSM_Model Epoch 2/4: 100%|███████████████████████████| 469/469 [00:20<00:00, 22.59it/s, loss=0.186]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FGSM_Model Accuracy: 98.49%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FGSM_Model Epoch 3/4: 100%|███████████████████████████| 469/469 [00:20<00:00, 22.43it/s, loss=0.132]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FGSM_Model Accuracy: 98.78%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FGSM_Model Epoch 4/4: 100%|██████████████████████████| 469/469 [00:21<00:00, 21.97it/s, loss=0.0938]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FGSM_Model Accuracy: 98.86%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PGD_Model Epoch 1/4: 100%|████████████████████████████| 469/469 [00:32<00:00, 14.37it/s, loss=0.132]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PGD_Model Accuracy: 97.50%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PGD_Model Epoch 2/4: 100%|███████████████████████████| 469/469 [00:32<00:00, 14.40it/s, loss=0.0921]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PGD_Model Accuracy: 98.56%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PGD_Model Epoch 3/4: 100%|████████████████████████████| 469/469 [00:33<00:00, 14.21it/s, loss=0.119]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PGD_Model Accuracy: 98.95%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PGD_Model Epoch 4/4: 100%|███████████████████████████| 469/469 [00:32<00:00, 14.41it/s, loss=0.0208]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PGD_Model Accuracy: 98.99%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRADES_Model Epoch 1/4: 100%|█████████████████████████| 469/469 [00:48<00:00,  9.62it/s, loss=0.236]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRADES_Model Accuracy: 98.16%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRADES_Model Epoch 2/4: 100%|████████████████████████| 469/469 [01:04<00:00,  7.27it/s, loss=0.0677]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRADES_Model Accuracy: 98.61%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRADES_Model Epoch 3/4: 100%|████████████████████████| 469/469 [01:06<00:00,  7.07it/s, loss=0.0799]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRADES_Model Accuracy: 98.66%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRADES_Model Epoch 4/4: 100%|█████████████████████████| 469/469 [01:09<00:00,  6.72it/s, loss=0.184]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRADES_Model Accuracy: 98.84%\n"
     ]
    }
   ],
   "source": [
    "def test_all_models():\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    epochs = 4  # 为鲁棒训练适当增加训练轮数\n",
    "\n",
    "    # FGSM 对抗训练\n",
    "    model_fgsm = SimpleCNN()\n",
    "    train_fgsm(model_fgsm, train_loader, test_loader, epochs, device)\n",
    "\n",
    "    # PGD 对抗训练\n",
    "    model_pgd = SimpleCNN()\n",
    "    train_pgd(model_pgd, train_loader, test_loader, epochs, device)\n",
    "\n",
    "    # TRADES 对抗训练\n",
    "    model_trades = SimpleCNN()\n",
    "    train_trades(model_trades, train_loader, test_loader, epochs, device)\n",
    "\n",
    "test_all_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 步骤二：使用FGSM、PGD Attack、C&W来评估模型的对抗鲁棒性\n",
    "> FGSM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_22200\\2570958830.py:23: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(weight_path, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_before=0.99 accuracy_after=0.98 attack_success_rate=0.02 avg_perturbation=2.80\n",
      "fgsm\n",
      "accuracy_before=0.99 accuracy_after=0.98 attack_success_rate=0.02 avg_perturbation=2.80\n",
      "pgd\n",
      "accuracy_before=0.98 accuracy_after=0.98 attack_success_rate=0.02 avg_perturbation=nan\n",
      "trades\n"
     ]
    }
   ],
   "source": [
    "stats_fgsm_trained = evaluate_fgsm(SimpleCNN, \"FGSM_Model.pth\", test_loader, epsilon, num_samples)\n",
    "print(f\"fgsm\")\n",
    "\n",
    "stats_pgd_trained = evaluate_fgsm(SimpleCNN, \"PGD_Model.pth\", test_loader, epsilon, num_samples)\n",
    "print(f\"pgd\")\n",
    "\n",
    "stats_trades_trained = evaluate_fgsm(SimpleCNN, \"TRADES_Model.pth\", test_loader, epsilon, num_samples)\n",
    "print(f\"trades\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> PGD Attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_22200\\3941996626.py:34: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(weight_path, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_before=0.99 accuracy_after=0.99 attack_success_rate=0.01 avg_perturbation=nan\n",
      "fgsm\n",
      "accuracy_before=0.99 accuracy_after=0.99 attack_success_rate=0.01 avg_perturbation=nan\n",
      "pgd\n",
      "accuracy_before=0.98 accuracy_after=0.98 attack_success_rate=0.02 avg_perturbation=nan\n",
      "trades\n"
     ]
    }
   ],
   "source": [
    "stats_fgsm_trained = evaluate_pgd(SimpleCNN, \"FGSM_Model.pth\", test_loader, num_samples)\n",
    "print(f\"fgsm\")\n",
    "stats_pgd_trained = evaluate_pgd(SimpleCNN, \"PGD_Model.pth\", test_loader, num_samples)\n",
    "print(f\"pgd\")\n",
    "stats_trades_trained = evaluate_pgd(SimpleCNN, \"TRADES_Model.pth\", test_loader, num_samples)\n",
    "print(f\"trades\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> C&W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_22200\\3570220852.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(weight_path, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_before=0.99 accuracy_after=0.72 attack_success_rate=0.28 avg_perturbation=25.99\n",
      "fgsm\n",
      "accuracy_before=0.99 accuracy_after=0.91 attack_success_rate=0.09 avg_perturbation=25.67\n",
      "pgd\n",
      "accuracy_before=0.98 accuracy_after=0.59 attack_success_rate=0.41 avg_perturbation=25.91\n",
      "trades\n"
     ]
    }
   ],
   "source": [
    "stats_fgsm_trained = evaluate_cw(SimpleCNN, \"FGSM_Model.pth\", test_loader, num_samples)\n",
    "print(f\"fgsm\")\n",
    "stats_pgd_trained = evaluate_cw(SimpleCNN, \"PGD_Model.pth\", test_loader, num_samples)\n",
    "print(f\"pgd\")\n",
    "stats_trades_trained = evaluate_cw(SimpleCNN, \"TRADES_Model.pth\", test_loader, num_samples)\n",
    "print(f\"trades\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 步骤三：分析对抗训练对模型性能影响\n",
    "> FGSM\n",
    "\n",
    "| |accuracy_before|accuracy_after|attack_success_rate|avg_perturbation|\n",
    "|----|----|----|----|----|\n",
    "|原训练|0.99|0.94|0.06|2.80|\n",
    "|fgsm|0.99|0.98|0.02|2.80|\n",
    "|pgd|0.99|0.98|0.02|2.80|\n",
    "|trades|0.99|0.98|0.02|nan|\n",
    "\n",
    "> PGD Attack\n",
    "\n",
    "| |accuracy_before|accuracy_after|attack_success_rate|avg_perturbation|\n",
    "|----|----|----|----|----|\n",
    "|原训练|0.99|0.95|0.05|1.40|\n",
    "|fgsm|0.99|0.99|0.01|nan|\n",
    "|pgd|0.99|0.99|0.01|nan|\n",
    "|trades|0.98|0.98|0.02|nan|\n",
    "\n",
    "> C&W\n",
    "\n",
    "| |accuracy_before|accuracy_after|attack_success_rate|avg_perturbation|\n",
    "|----|----|----|----|----|\n",
    "|原训练|0.99|0.90|0.10|25.80|\n",
    "|fgsm|0.99|0.72|0.28|25.99|\n",
    "|pgd|0.99|0.91|0.09|25.67|\n",
    "|trades|0.98|0.59|0.41|25.91|\n",
    "\n",
    "> FGSM-based Adversarial Training 和 PGD Adversarial Training对鲁棒性均有轻微的提高，攻击成功率有所下降，但在C&W中仅有pgd实现了攻击成功率有所下降。\n",
    "> 准确性并未降低。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 步骤四：对于C&W攻击成功率上升的分析\n",
    "> - 攻击方式差异  \n",
    "> C&W（Carlini & Wagner）攻击与 FGSM / PGD 属于不同类型  \n",
    "\n",
    "| 攻击类型     | 描述            | 优化目标        |\n",
    "| -------- | ------------- | ----------- |\n",
    "| FGSM | 基于梯度的“最大扰动”攻击 | 快速提升损失      |\n",
    "| C\\&W     | 基于优化的“最小扰动”攻击 | 最小扰动前提下改变分类 |\n",
    "\n",
    "> - 对抗训练“过拟合”某种攻击  \n",
    "> FGSM 对抗训练模型，对该类攻击增强鲁棒性，但对结构不同的攻击（如 C&W）泛化性差：  \n",
    "> FGSM 对抗训练强调：让模型适应“朝着最大梯度方向”的扰动。  \n",
    "> C&W 攻击并不一定沿最大梯度方向优化，它优化的 loss 是 margin-based（比如 ||δ|| + confidence margin）。  \n",
    "> FGSM训练模型对精细扰动反而更脆弱，可能因为它只在大幅梯度方向训练，缺乏对精细扰动的判别能力；  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task-3:深度模型后门攻击鲁棒性分析\n",
    "### 步骤一：选择BadNet Attack和Clean Lable Attack来评估SimpleCNN\n",
    "> BadNet Attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_badnet_trigger(image, trigger_size=3):\n",
    "    image = image.clone()\n",
    "    _, h, w = image.shape\n",
    "    image[:, h - trigger_size:h, w - trigger_size:w] = 1.0  # 白色方块\n",
    "    return image\n",
    "\n",
    "def add_blend_trigger(image, alpha=0.2):\n",
    "    image = image.clone()\n",
    "    noise = torch.rand_like(image) * 2 - 1  # 生成[-1, 1]范围的噪声\n",
    "    blended_image = (1 - alpha) * image + alpha * noise\n",
    "    blended_image = torch.clamp(blended_image, -1, 1)\n",
    "    return blended_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_backdoor_attacks(model, test_dataset, device, attack_type='BadNet', target_label=0, num_samples=50):\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "\n",
    "    # 随机选择 num_samples 个测试样本\n",
    "    indices = random.sample(range(len(test_dataset)), num_samples)\n",
    "    clean_images = []\n",
    "    clean_labels = []\n",
    "    triggered_images = []\n",
    "\n",
    "    for idx in indices:\n",
    "        image, label = test_dataset[idx]\n",
    "        clean_images.append(image)\n",
    "        clean_labels.append(label)\n",
    "\n",
    "        # 添加触发器\n",
    "        if attack_type == 'BadNet':\n",
    "            triggered_image = add_badnet_trigger(image)\n",
    "        elif attack_type == 'Blend':\n",
    "            triggered_image = add_blend_trigger(image)\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported attack type.\")\n",
    "\n",
    "        triggered_images.append(triggered_image)\n",
    "\n",
    "    # 转换为张量\n",
    "    clean_images = torch.stack(clean_images).to(device)\n",
    "    clean_labels = torch.tensor(clean_labels).to(device)\n",
    "    triggered_images = torch.stack(triggered_images).to(device)\n",
    "    target_labels = torch.full((num_samples,), target_label, dtype=torch.long).to(device)\n",
    "\n",
    "    # 评估干净样本准确率\n",
    "    with torch.no_grad():\n",
    "        outputs = model(clean_images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        clean_accuracy = (predicted == clean_labels).float().mean().item()\n",
    "\n",
    "    # 评估后门攻击成功率\n",
    "    with torch.no_grad():\n",
    "        outputs = model(triggered_images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        asr = (predicted == target_labels).float().mean().item()\n",
    "\n",
    "    print(f\"[{attack_type} Attack] Clean Accuracy: {clean_accuracy * 100:.2f}%, ASR: {asr * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[BadNet Attack] Clean Accuracy: 98.00%, ASR: 26.00%\n",
      "[Blend Attack] Clean Accuracy: 98.00%, ASR: 12.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_22200\\3088814080.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('FGSM_Model.pth'))  # 替换为您的模型路径\n"
     ]
    }
   ],
   "source": [
    "# 加载模型\n",
    "model = SimpleCNN()\n",
    "model.load_state_dict(torch.load('FGSM_Model.pth'))  # 替换为您的模型路径\n",
    "\n",
    "# 加载测试数据集\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5])\n",
    "])\n",
    "test_dataset = torchvision.datasets.MNIST('dataset/mnist-pytorch', train=False, transform=transform)\n",
    "\n",
    "# 设置设备\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 评估 BadNet Attack\n",
    "test_backdoor_attacks(model, test_dataset, device, attack_type='BadNet', target_label=0, num_samples=50)\n",
    "\n",
    "# 评估 Blend Attack\n",
    "test_backdoor_attacks(model, test_dataset, device, attack_type='Blend', target_label=0, num_samples=50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 步骤二：探究对抗训练与非对抗训练面对后门攻击时的ASR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[BadNet Attack] Clean Accuracy: 98.00%, ASR: 10.00%\n",
      "[Blend Attack] Clean Accuracy: 98.00%, ASR: 4.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_22200\\2235262358.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('M1.pth'))  # 替换为您的模型路径\n"
     ]
    }
   ],
   "source": [
    "# 加载模型\n",
    "model = SimpleCNN()\n",
    "model.load_state_dict(torch.load('M1.pth'))  # 替换为您的模型路径\n",
    "\n",
    "# 加载测试数据集\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5])\n",
    "])\n",
    "test_dataset = torchvision.datasets.MNIST('dataset/mnist-pytorch', train=False, transform=transform)\n",
    "\n",
    "# 设置设备\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 评估 BadNet Attack\n",
    "test_backdoor_attacks(model, test_dataset, device, attack_type='BadNet', target_label=0, num_samples=50)\n",
    "\n",
    "# 评估 Blend Attack\n",
    "test_backdoor_attacks(model, test_dataset, device, attack_type='Blend', target_label=0, num_samples=50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 显然，在非对抗训练时ASR更低，现分析可能原因：  \n",
    "> - 后门攻击 ≠ 对抗攻击  \n",
    "> 后门攻击（Backdoor Attack）：攻击者在训练阶段引入带触发器的图像，并强行将其标签设为目标类，模型在训练中“记住”了触发器 → label 的关联，这是一个训练时注入的漏洞。  \n",
    "> 对抗攻击（Adversarial Attack）：攻击者在测试阶段，针对当前模型参数，添加细微扰动使预测错误，是基于模型梯度的泛化性漏洞。  \n",
    "> 所以它们利用的模型脆弱性本质不同，一个是训练过程种下的逻辑漏洞，一个是测试时找漏洞。  \n",
    "> - 对抗训练让模型更依赖“强特征”  \n",
    "> 对抗训练倾向于增强模型对抗扰动的鲁棒性，常常会“压制”那些对预测不稳定的脆弱特征（weak features）。  \n",
    "> 后门触发器是非常明显、强烈的图像特征（例如白块、强噪声等），比自然图像中微弱的特征更显眼。  \n",
    "> 于是，对抗训练后的模型 更加依赖这些显著、可辨识的“强特征”，后门触发器恰好就属于这类更容易激发模型的“记忆”。  \n",
    "> 总结一句话：对抗训练“压制自然特征、增强显著特征”，后门触发器被误判为“强特征”而更容易被识别。  \n",
    "> - 对抗训练不会自动防御后门触发器  \n",
    "> 对抗训练是为了防止：x + 小扰动 δ → 预测结果错误。它优化的是模型对自然样本的连续性。  \n",
    "> 而 BadNet/Blend 等后门攻击是：加入非连续、明显的人造图案（甚至跨类别干扰）。攻击目标是训练阶段修改标签的那一批触发样本（非对抗扰动！）  \n",
    "> 所以：对抗训练虽然提高了模型对自然扰动的鲁棒性，但对显式人为注入的 trigger pattern 并没有学习到“排斥”行为，反而可能强化了对其的响应。  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
